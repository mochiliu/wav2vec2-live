{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2057386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'HDA NVidia: HDMI 0 (hw:0,3)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'HDA NVidia: HDMI 1 (hw:0,7)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': 'HDA NVidia: HDMI 2 (hw:0,8)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n",
      "{'index': 3, 'structVersion': 2, 'name': 'HDA NVidia: HDMI 3 (hw:0,9)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n",
      "{'index': 4, 'structVersion': 2, 'name': 'HDA NVidia: HDMI 4 (hw:0,10)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'HDA NVidia: HDMI 5 (hw:0,11)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n",
      "{'index': 6, 'structVersion': 2, 'name': 'sof-hda-dsp: - (hw:1,0)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.005333333333333333, 'defaultLowOutputLatency': 0.005333333333333333, 'defaultHighInputLatency': 0.032, 'defaultHighOutputLatency': 0.032, 'defaultSampleRate': 48000.0}\n",
      "{'index': 7, 'structVersion': 2, 'name': 'sof-hda-dsp: - (hw:1,3)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005333333333333333, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.032, 'defaultSampleRate': 48000.0}\n",
      "{'index': 8, 'structVersion': 2, 'name': 'sof-hda-dsp: - (hw:1,4)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005333333333333333, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.032, 'defaultSampleRate': 48000.0}\n",
      "{'index': 9, 'structVersion': 2, 'name': 'sof-hda-dsp: - (hw:1,5)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005333333333333333, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.032, 'defaultSampleRate': 48000.0}\n",
      "{'index': 10, 'structVersion': 2, 'name': 'sof-hda-dsp: - (hw:1,6)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.005333333333333333, 'defaultLowOutputLatency': -1.0, 'defaultHighInputLatency': 0.032, 'defaultHighOutputLatency': -1.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 11, 'structVersion': 2, 'name': 'sof-hda-dsp: - (hw:1,7)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.016, 'defaultLowOutputLatency': -1.0, 'defaultHighInputLatency': 0.096, 'defaultHighOutputLatency': -1.0, 'defaultSampleRate': 16000.0}\n",
      "{'index': 12, 'structVersion': 2, 'name': 'hdmi', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': -1.0, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': -1.0, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:618:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1052:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_dsnoop.c:618:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1052:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1052:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "p = pyaudio.PyAudio()\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04dac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import webrtcvad\n",
    "from wav2vec2_inference import Wave2Vec2Inference\n",
    "import numpy as np\n",
    "import threading\n",
    "import copy\n",
    "import time\n",
    "from sys import exit\n",
    "import contextvars\n",
    "from queue import  Queue\n",
    "\n",
    "\n",
    "class LiveWav2Vec2():\n",
    "    exit_event = threading.Event()\n",
    "    def __init__(self, model_name, device_name=\"default\"):\n",
    "        self.model_name = model_name\n",
    "        self.device_name = device_name\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"stop the asr process\"\"\"\n",
    "        LiveWav2Vec2.exit_event.set()\n",
    "        self.asr_input_queue.put(\"close\")\n",
    "        print(\"asr stopped\")\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"start the asr process\"\"\"\n",
    "        self.asr_output_queue = Queue()\n",
    "        self.asr_input_queue = Queue()\n",
    "        self.asr_process = threading.Thread(target=LiveWav2Vec2.asr_process, args=(\n",
    "            self.model_name, self.asr_input_queue, self.asr_output_queue,))\n",
    "        self.asr_process.start()\n",
    "        time.sleep(5)  # start vad after asr model is loaded\n",
    "        self.vad_process = threading.Thread(target=LiveWav2Vec2.vad_process, args=(\n",
    "            self.device_name, self.asr_input_queue,))\n",
    "        self.vad_process.start()\n",
    "\n",
    "    def vad_process(device_name, asr_input_queue):\n",
    "        vad = webrtcvad.Vad()\n",
    "        vad.set_mode(1)\n",
    "\n",
    "        audio = pyaudio.PyAudio()\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 16000\n",
    "        # A frame must be either 10, 20, or 30 ms in duration for webrtcvad\n",
    "        FRAME_DURATION = 30\n",
    "        CHUNK = int(RATE * FRAME_DURATION / 1000)\n",
    "        RECORD_SECONDS = 50\n",
    "\n",
    "        microphones = LiveWav2Vec2.list_microphones(audio)\n",
    "        assert len(microphones) > 0, \"microphone with appropriate sampling rate not found\"\n",
    "        selected_input_device_id = LiveWav2Vec2.get_input_device_id(\n",
    "            device_name, microphones)\n",
    "\n",
    "        stream = audio.open(input_device_index=selected_input_device_id,\n",
    "                            format=FORMAT,\n",
    "                            channels=CHANNELS,\n",
    "                            rate=RATE,\n",
    "                            input=True,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "\n",
    "        frames = b''\n",
    "        while True:\n",
    "            if LiveWav2Vec2.exit_event.is_set():\n",
    "                break\n",
    "            frame = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            is_speech = vad.is_speech(frame, RATE)\n",
    "            if is_speech:\n",
    "                frames += frame\n",
    "            else:\n",
    "                if len(frames) > 1:\n",
    "                    asr_input_queue.put(frames)\n",
    "                frames = b''\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "    def asr_process(model_name, in_queue, output_queue):\n",
    "        wave2vec_asr = Wave2Vec2Inference(model_name)\n",
    "\n",
    "        print(\"\\nlistening to your voice\\n\")\n",
    "        while True:\n",
    "            audio_frames = in_queue.get()\n",
    "            if audio_frames == \"close\":\n",
    "                break\n",
    "\n",
    "            float64_buffer = np.frombuffer(\n",
    "                audio_frames, dtype=np.int16) / 32767\n",
    "            start = time.perf_counter()\n",
    "            text = wave2vec_asr.buffer_to_text(float64_buffer).lower()\n",
    "            inference_time = time.perf_counter()-start\n",
    "            sample_length = len(float64_buffer) / 16000  # length in sec\n",
    "            if text != \"\":\n",
    "                output_queue.put([text,sample_length,inference_time])\n",
    "\n",
    "    def get_input_device_id(device_name, microphones):\n",
    "        for device in microphones:\n",
    "            if device_name in device[1]:\n",
    "                return device[0]\n",
    "        return microphones[0][0] #return the first valid microphone if device not found\n",
    "\n",
    "    def list_microphones(pyaudio_instance):\n",
    "        info = pyaudio_instance.get_host_api_info_by_index(0)\n",
    "        numdevices = info.get('deviceCount')\n",
    "\n",
    "        result = []\n",
    "        for i in range(0, numdevices):\n",
    "            if ((pyaudio_instance.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0) and ((pyaudio_instance.get_device_info_by_host_api_device_index(0, i).get('defaultSampleRate')) == RATE):\n",
    "                name = pyaudio_instance.get_device_info_by_host_api_device_index(\n",
    "                    0, i).get('name')\n",
    "                result += [[i, name]]\n",
    "        return result\n",
    "\n",
    "    def get_last_text(self):\n",
    "        \"\"\"returns the text, sample length and inference time in seconds.\"\"\"\n",
    "        return self.asr_output_queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515c8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr = LiveWav2Vec2(\"facebook/wav2vec2-large-960h-lv60-self\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc312fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 'sof-hda-dsp: - (hw:1,7)']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LiveWav2Vec2.list_microphones(pyaudio.PyAudio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "LiveWav2Vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c76511",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a592f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\" in 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7df63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d061e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
